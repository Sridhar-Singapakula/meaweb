(this.webpackJsonpclient=this.webpackJsonpclient||[]).push([[0],{20:function(e,t,i){},21:function(e,t,i){},33:function(e,t,i){},34:function(e,t,i){},35:function(e,t,i){},36:function(e,t,i){},37:function(e,t,i){},38:function(e,t,i){},39:function(e,t,i){},40:function(e,t,i){},41:function(e,t,i){"use strict";i.r(t);var s=i(1),n=i.n(s),a=i(13),r=i.n(a),o=(i(20),i(7)),c=i(14),l=i.n(c),d=i.p+"static/media/logo.09cce902.png",h=(i(21),i(22),i(23),i(0));var m=()=>{const[e,t]=Object(s.useState)(!1),[i,n]=Object(s.useState)(!1),a=()=>{n(!1)};return Object(s.useEffect)((()=>{l.a.init()}),[]),Object(h.jsx)("header",{id:"header",className:"fixed-top d-flex align-items-center",children:Object(h.jsxs)("div",{className:"container  align-items-center justify-content-between",style:{display:"flex"},children:[Object(h.jsx)(o.b,{to:"/",style:{display:"flex"},children:Object(h.jsx)("div",{children:Object(h.jsx)("a",{href:"/",className:"logo me-auto",children:Object(h.jsx)("img",{src:d,alt:""})})})}),Object(h.jsxs)("nav",{id:"navbar",className:"navbar order-last order-lg-0 ".concat(i?"mobile-nav-open":""),children:[Object(h.jsxs)("ul",{children:[Object(h.jsx)("li",{onClick:a,children:Object(h.jsx)("a",{className:"nav-link scrollto active",href:"/",children:"Models"})}),Object(h.jsx)("li",{onClick:a,children:Object(h.jsx)("a",{className:"nav-link scrollto",href:"/GC",children:Object(h.jsx)("button",{className:"button-4",children:"Community"})})}),Object(h.jsx)("li",{onClick:a,children:Object(h.jsxs)("a",{className:"nav-link scrollto",href:"#",children:[Object(h.jsx)("i",{class:"bi bi-person-circle",style:{color:"#86B6F6",fontSize:"22px",marginRight:"8px"}}),"Sridhar"]})})]}),Object(h.jsx)("i",{className:"bi bi-list mobile-nav-toggle",onClick:()=>{n(!i)}})]})]})})};i(33),i(34);var j=()=>{const[e,t]=Object(s.useState)(""),[i,n]=Object(s.useState)(null);return Object(h.jsxs)("div",{children:[Object(h.jsx)("input",{className:"form_input",type:"text",placeholder:"Enter data for query",value:e,onChange:e=>{t(e.target.value)}}),Object(h.jsx)("button",{className:"form_button",onClick:async()=>{try{const t={inputs:e},i=await fetch("https://api-inference.huggingface.co/models/facebook/bart-large-cnn",{method:"POST",headers:{Authorization:"Bearer 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","Content-Type":"application/json"},body:JSON.stringify(t)}),s=await i.json();n(s)}catch(t){console.error("Error querying:",t)}},children:"Summarize"}),i&&Object(h.jsxs)("div",{children:[Object(h.jsx)("h2",{children:"Result:"}),Object(h.jsx)("div",{className:"result_Div",style:{width:"400px",height:"500px",overflowY:"auto",overflowX:"hidden"},children:Object(h.jsx)("p",{children:i[0].summary_text})})]})]})};var b=()=>{const e=Object(s.useRef)(null);return Object(h.jsxs)("div",{children:[Object(h.jsx)(m,{}),Object(h.jsxs)("section",{className:"t1",children:[Object(h.jsxs)("div",{className:"desc1",children:[Object(h.jsx)("h4",{children:"BART (large-sized model), fine-tuned on CNN Daily Mail"}),Object(h.jsx)("p",{children:"BART model pre-trained on English language, and fine-tuned on CNN Daily Mail. It was introduced in the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Lewis et al. and first released in [this repository (https://github.com/pytorch/fairseq/tree/master/examples/bart)."}),Object(h.jsx)("p",{children:"Disclaimer: The team releasing ResNet did not write a model card for this model so this model card has been written by the Hugging Face team."}),Object(h.jsx)("h4",{children:"Model description"}),Object(h.jsx)("p",{children:"BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text."}),Object(h.jsx)("p",{children:"BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}),Object(h.jsx)("img",{src:"https://www.bankinghub.eu/wp-content/uploads/2023/05/text-summarization-ai-training-prediction-modes-bankinghub.png",className:"desc1_img"}),Object(h.jsx)("h4",{children:"Intended uses & limitations"}),Object(h.jsx)("p",{children:"You can use the raw model for image classification. See the model hub to look for fine-tuned versions on a task that interests you."}),Object(h.jsx)("h4",{children:"How to use"}),Object(h.jsx)("p",{children:"Here is how to use this model to classify an image of the COCO 2017 dataset into one of the 1,000 ImageNet classes:"}),Object(h.jsxs)("div",{style:{display:"flex",flexDirection:"row",justifyContent:"space-between",gap:"20px"},children:[Object(h.jsx)("div",{className:"area_",children:Object(h.jsx)("textarea",{className:"desc_code",ref:e,readOnly:!0,value:'from transformers import pipeline\n\n    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")\n    \n    ARTICLE = """ New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n    A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n    Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared "I do" five more times, sometimes only within two weeks of each other.\n    In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her "first and only" marriage.\n    Barrientos, now 39, is facing two criminal counts of "offering a false instrument for filing in the first degree," referring to her false statements on the\n    2010 marriage license application, according to court documents.\n    Prosecutors said the marriages were part of an immigration scam.\n    On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n    After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n    Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n    All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n    Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n    Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n    The case was referred to the Bronx District Attorney\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\'s\n    Investigation Division. Seven of the men are from so-called "red-flagged" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n    Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n    If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n    """\n    print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))\n    [{\'summary_text\': \'Liana Barrientos, 39, is charged with two counts of "offering a false instrument for filing in the first degree" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.\'}]',style:{width:"100%",minHeight:"600px",fontFamily:"monospace"}})}),Object(h.jsx)("div",{className:"copy",children:Object(h.jsx)("button",{onClick:()=>{e.current&&(e.current.select(),document.execCommand("copy"))},className:"cpy",children:"\u2398 Copy"})})]})]}),Object(h.jsxs)("div",{className:"try",children:[Object(h.jsx)("img",{src:"https://assets-global.website-files.com/5f7ece8a7da656e8a25402bc/6375f420953f04fdc56aedd8_summarize.png",className:"final_img",style:{width:"500px"}}),Object(h.jsx)("h4",{children:"Try it Out"}),Object(h.jsx)("div",{children:Object(h.jsx)(j,{})})]})]})]})};i(35);var u=()=>{const[e,t]=Object(s.useState)(""),[i,n]=Object(s.useState)(null);return Object(h.jsxs)("div",{children:[Object(h.jsx)("input",{className:"form_input",type:"text",placeholder:"Enter data for query",value:e,onChange:e=>{t(e.target.value)}}),Object(h.jsx)("button",{className:"form_button",onClick:async()=>{try{const t={inputs:e},i=await fetch("https://api-inference.huggingface.co/models/google/gemma-7b",{method:"POST",headers:{Authorization:"Bearer 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","Content-Type":"application/json"},body:JSON.stringify(t)}),s=await i.json();n(s)}catch(t){console.error("Error querying:",t)}},children:"Generate Text"}),i&&Object(h.jsxs)("div",{children:[Object(h.jsx)("h2",{children:"Result:"}),Object(h.jsx)("div",{className:"result_Div",style:{width:"400px",height:"500px",overflowY:"auto",overflowX:"hidden"},children:Object(h.jsx)("p",{children:i[0].generated_text})})]})]})};var g=()=>{const e=Object(s.useRef)(null);return Object(h.jsxs)("div",{children:[Object(h.jsx)(m,{}),Object(h.jsxs)("section",{className:"t1",children:[Object(h.jsxs)("div",{className:"desc1",children:[Object(h.jsx)("h4",{children:"BART (large-sized model), fine-tuned on CNN Daily Mail"}),Object(h.jsx)("p",{children:"BART model pre-trained on English language, and fine-tuned on CNN Daily Mail. It was introduced in the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Lewis et al. and first released in [this repository (https://github.com/pytorch/fairseq/tree/master/examples/bart)."}),Object(h.jsx)("p",{children:"Disclaimer: The team releasing ResNet did not write a model card for this model so this model card has been written by the Hugging Face team."}),Object(h.jsx)("h4",{children:"Model description"}),Object(h.jsx)("p",{children:"BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text."}),Object(h.jsx)("p",{children:"BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}),Object(h.jsx)("img",{src:"https://www.bankinghub.eu/wp-content/uploads/2023/05/text-summarization-ai-training-prediction-modes-bankinghub.png",className:"desc1_img"}),Object(h.jsx)("h4",{children:"Intended uses & limitations"}),Object(h.jsx)("p",{children:"You can use the raw model for image classification. See the model hub to look for fine-tuned versions on a task that interests you."}),Object(h.jsx)("h4",{children:"How to use"}),Object(h.jsx)("p",{children:"Here is how to use this model to classify an image of the COCO 2017 dataset into one of the 1,000 ImageNet classes:"}),Object(h.jsxs)("div",{style:{display:"flex",flexDirection:"row",justifyContent:"space-between",gap:"20px"},children:[Object(h.jsx)("div",{className:"area_",children:Object(h.jsx)("textarea",{className:"desc_code",ref:e,readOnly:!0,value:'from transformers import pipeline\n\n    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")\n    \n    ARTICLE = """ New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n    A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n    Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared "I do" five more times, sometimes only within two weeks of each other.\n    In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her "first and only" marriage.\n    Barrientos, now 39, is facing two criminal counts of "offering a false instrument for filing in the first degree," referring to her false statements on the\n    2010 marriage license application, according to court documents.\n    Prosecutors said the marriages were part of an immigration scam.\n    On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n    After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n    Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n    All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n    Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n    Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n    The case was referred to the Bronx District Attorney\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\'s\n    Investigation Division. Seven of the men are from so-called "red-flagged" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n    Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n    If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n    """\n    print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))\n    [{\'summary_text\': \'Liana Barrientos, 39, is charged with two counts of "offering a false instrument for filing in the first degree" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.\'}]',style:{width:"100%",minHeight:"600px",fontFamily:"monospace"}})}),Object(h.jsx)("div",{className:"copy",children:Object(h.jsx)("button",{onClick:()=>{e.current&&(e.current.select(),document.execCommand("copy"))},className:"cpy",children:"\u2398 Copy"})})]})]}),Object(h.jsxs)("div",{className:"try",children:[Object(h.jsx)("img",{src:"https://assets-global.website-files.com/5f7ece8a7da656e8a25402bc/6375f420953f04fdc56aedd8_summarize.png",className:"final_img",style:{width:"500px"}}),Object(h.jsx)("h4",{children:"Try it Out"}),Object(h.jsx)("div",{children:Object(h.jsx)(u,{})})]})]})]})};i(36),i.p,i(37);var p=e=>{let{model:t}=e;return Object(h.jsxs)("div",{className:"MLmodels",children:[Object(h.jsxs)("div",{className:"info_models",children:[Object(h.jsx)("div",{className:"model_div",children:"Model"}),Object(h.jsx)("h2",{children:t.modelName}),Object(h.jsx)("p",{className:"models_div_p",children:t.description}),Object(h.jsxs)("div",{className:"company",children:[Object(h.jsxs)("p",{className:"by",children:[" ",Object(h.jsx)("span",{dangerouslySetInnerHTML:{__html:t.logo}})," ",t.developedBy," "]}),Object(h.jsx)("p",{children:Object(h.jsx)("i",{class:"bi bi-github",style:{fontSize:"20px"}})}),Object(h.jsxs)("p",{children:[Object(h.jsx)("i",{class:"bi bi-star-fill",style:{color:" #FFD700"}})," ",t.rating]})]})]}),Object(h.jsx)("div",{children:Object(h.jsx)("img",{src:t.imgUrl,alt:"Model",className:"image_1"})})]})};var f=[{modelName:"Image Classifier",description:"Image Classification is a fundamental task in vision recognition that aims to understand and categorize an image as a whole under a specific label.",imgUrl:"https://b2633864.smushcdn.com/2633864/wp-content/uploads/2020/06/keras_classifier_object_detector_result02_update.png?lossy=2&strip=1&webp=1",developedBy:"Apple",logo:'<i class="bi bi-apple"></i>',githubLink:"https://github.com/example/audio-model-repo",rating:200,category:"Image",LinkTo:"/ImageClassifierPage",isValid:"True"},{modelName:"Summarization",description:"Generate summaries of paragraphs or articles in one click. Our AI summarizer tool provides quick, concise copy that identifies important points in any text.",imgUrl:"https://sparkmailapp.com/img/blog/ai-summary-en.png?1592587369412",developedBy:"Google",logo:'<i class="bi bi-google"></i>',githubLink:"https://github.com/example/audio-model-repo",rating:110,category:"Text",LinkTo:"/Summarization",isValid:"True"},{modelName:"Text Generation",description:"Audio recognition, also known as sound or audio classification, is a technology that involves the identification and categorization of audio signals or sounds.",imgUrl:"https://www.contentserv.com/hs-fs/hubfs/blog/EN/nlp-nlg-automated-text-generation-is-powering-content-creation.png?width=1140&height=700&name=nlp-nlg-automated-text-generation-is-powering-content-creation.png",developedBy:"Meta",logo:'<i class="bi bi-meta"></i>',githubLink:"https://github.com/example/audio-model-repo",rating:212,category:"Audio",LinkTo:"/TextGeneration",isValid:"True"},{modelName:"Image Segmentation",description:"Identifies a variety of concepts in images and video including objects, themes, and more. Trained with over 10,000 concepts and 20M images.",imgUrl:"https://media.licdn.com/dms/image/D5612AQGWPRQl8czM5A/article-cover_image-shrink_600_2000/0/1684594625825?e=2147483647&v=beta&t=rirlHANBk3AYalUPf7r4HNWiqoE2xY7NsVTJ2FwLQLM",developedBy:"Meta",logo:'<i class="bi bi-meta"></i>',githubLink:"https://github.com/example/nlp-model-repo",rating:100,LinkTo:"/ImageDetection",category:"Image",isValid:"False"},{modelName:"TextToSpeech",description:"Audio recognition, also known as sound or audio classification, is a technology that involves the identification and categorization of audio signals or sounds.",imgUrl:"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrHro6d3BTw7ZZ4IXgfb6_8aESB7-SsWfelDSSInZVamiMSnYpBZzGBaZBBrWxWwYgLqOHuOtroGvGjxrwzdUkhjwuIvM1u6chIblGKS1gQ6JVkjXr-Vztyk2zoYb1ylvhNgLgC5q6M-7LaiXT1xnAT96DvkPx89APNb8JEaz-1mnMRcfaOYYBHzQL/s1600/Text%20to%20Speech%20-%20Social%20-%201024x512.png",developedBy:"Meta",logo:'<i class="bi bi-meta"></i>',githubLink:"https://github.com/example/audio-model-repo",rating:212,category:"Audio",LinkTo:"/TextToSpeech",isValid:"False"},{modelName:"Audio Recognition",description:"Audio recognition, also known as sound or audio classification, is a technology that involves the identification and categorization of audio signals or sounds.",imgUrl:"https://www.shaip.com/wp-content/uploads/2022/10/Blog_Applications-of-Voice-Recognition-Technology.jpg",developedBy:"Google",logo:'<i class="bi bi-google"></i>',githubLink:"https://github.com/example/audio-model-repo",rating:512,category:"Audio",LinkTo:"/AudioRecognition",isValid:"False"}];const x=()=>{const[e,t]=Object(s.useState)(""),[i,n]=Object(s.useState)(f),a=i.filter((e=>"True"===e.isValid)),r=i.filter((e=>"False"===e.isValid));return Object(h.jsxs)("div",{children:[Object(h.jsx)(m,{}),Object(h.jsx)("section",{className:"head_",children:Object(h.jsxs)("div",{className:"main_atlan",children:[Object(h.jsx)("h4",{className:"main_h4",children:"Discover AI Brilliance: Join Our Global Community"}),Object(h.jsx)("p",{className:"main_p",children:"your one-stop destination for crafting powerful AI-driven applications. Uncover, create, and exchange innovative AI models, workflows, and app elements, all seamlessly integrated into Clarifai's user-friendly low code and no code platform."}),Object(h.jsxs)("div",{className:"main_under",children:[Object(h.jsx)("button",{className:"button-46",children:"More About Us"}),Object(h.jsx)("button",{className:"button-67",style:{textAlign:"center"},children:"Explore"})]}),Object(h.jsx)("p",{className:"main_p",children:"Do follow us on: "}),Object(h.jsxs)("ul",{className:"icons_",children:[Object(h.jsx)("i",{class:"bi bi-github"}),Object(h.jsx)("i",{class:"bi bi-linkedin",style:{color:"#0A66C2"}}),Object(h.jsx)("i",{class:"bi bi-twitter-x"}),Object(h.jsx)("i",{class:"bi bi-youtube",style:{color:"#CD201F"}})]})]})}),Object(h.jsxs)("section",{children:[Object(h.jsx)("h4",{className:"cards_h4",style:{textAlign:"center",marginTop:"30px"},children:"What makes us Different"}),Object(h.jsxs)("div",{className:"cards_atlan",children:[Object(h.jsxs)("div",{className:"card_2",children:[Object(h.jsxs)("div",{className:"card2_div",children:[Object(h.jsx)("i",{class:"bi bi-globe-europe-africa",style:{color:"white",fontSize:"20px",marginRight:"10px"}}),"Accessible"]}),Object(h.jsx)("p",{className:"cards_p",children:"Wherever  in the world"}),Object(h.jsx)("h2",{className:"card_h2",children:"24x7"})]}),Object(h.jsxs)("div",{className:"card_1",children:[Object(h.jsx)("i",{class:"bi bi-play-circle-fill",style:{fontSize:"35px",color:"white"}}),Object(h.jsx)("p",{className:"cards_p",children:"Daily users"}),Object(h.jsx)("h2",{className:"card_h2",children:"400+"})]}),Object(h.jsxs)("div",{className:"card_3",children:[Object(h.jsxs)("div",{className:"card2_div",children:[Object(h.jsx)("i",{class:"bi bi-graph-up-arrow",style:{color:"white",fontSize:"20px",marginRight:"10px"}}),"Growing"]}),Object(h.jsx)("p",{className:"cards_p",children:"Fast Growing Community"}),Object(h.jsx)("h2",{className:"card_h2",children:"ML models"})]})]})]}),Object(h.jsxs)("section",{className:"models",children:[Object(h.jsx)("h4",{className:"cards_h4",style:{textAlign:"center",marginTop:"30px"},children:"Explore Models By our community"}),Object(h.jsxs)("div",{className:"search_box",children:[Object(h.jsx)("input",{type:"text",placeholder:"Search by model name...",value:e,className:"search_bar",onChange:e=>t(e.target.value)}),Object(h.jsxs)("button",{onClick:()=>{const i=f.filter((t=>t.modelName.toLowerCase().includes(e.toLowerCase())));n(i),t("")},className:"button-46",children:[Object(h.jsx)("i",{class:"bi bi-search",style:{marginRight:"10px"}})," Search"]})]}),Object(h.jsxs)("div",{className:"MLmodels_",children:[Object(h.jsxs)("div",{children:[Object(h.jsx)("h2",{children:"Online Try Out Models"}),a.map(((e,t)=>Object(h.jsx)(o.b,{to:e.LinkTo,style:{textDecoration:"none"},children:Object(h.jsx)(p,{model:e})},t)))]}),Object(h.jsxs)("div",{children:[Object(h.jsx)("h2",{children:"GithubCode MLmodels"}),r.map(((e,t)=>Object(h.jsx)(o.b,{to:e.LinkTo,style:{textDecoration:"none"},children:Object(h.jsx)(p,{model:e})},t)))]})]})]}),Object(h.jsxs)("section",{className:"down_sec",children:[Object(h.jsxs)("div",{className:"down",children:[Object(h.jsx)("div",{className:"down_1",children:Object(h.jsx)("div",{style:{width:"70px",height:"70px",background:"rgb(219, 216, 249)",alignItems:"center",display:"flex",justifyContent:"center",borderRadius:"10px"},children:Object(h.jsx)("i",{class:"bi bi-discord",style:{fontSize:"30px",color:"rgb(99, 86, 238)"}})})}),Object(h.jsxs)("div",{className:"down_info",children:[Object(h.jsx)("h4",{children:"Join our Discord Channel"}),Object(h.jsx)("p",{children:"Post questions, talk to core engineers and share knowledge with other AI builders."}),Object(h.jsx)("p",{style:{textDecoration:"underline",color:"rgb(127, 153, 241)"},children:"Join Discord channel"})]})]}),Object(h.jsxs)("div",{className:"down",children:[Object(h.jsx)("div",{className:"down_1",children:Object(h.jsx)("div",{style:{width:"70px",height:"70px",background:"rgb(224, 247, 224)",alignItems:"center",display:"flex",justifyContent:"center",borderRadius:"10px"},children:Object(h.jsx)("i",{class:"bi bi-play-circle-fill",style:{fontSize:"30px",color:"rgb(7, 107, 7)"}})})}),Object(h.jsxs)("div",{className:"down_info",children:[Object(h.jsx)("h4",{children:"Community Video Tutorial"}),Object(h.jsx)("p",{children:"Post questions, talk to core engineers and share knowledge with other AI builders."}),Object(h.jsx)("p",{style:{textDecoration:"underline",color:"rgb(127, 153, 241)"},children:"Join as A member to our channel"})]})]})]}),Object(h.jsx)("section",{style:{textAlign:"center"},children:Object(h.jsxs)("p",{className:"last",children:["\xa9 2024 Polaris-All licensed content ",Object(h.jsx)("span",{style:{textDecoration:"underline",color:"rgb(27, 80, 139)"},children:"Community"})]})})]})};var O=i(2);i(38),i(39);var y=()=>{const[e,t]=Object(s.useState)(null),[i,n]=Object(s.useState)(null),[a,r]=Object(s.useState)(!1),[o,c]=Object(s.useState)(null),l=(Object(O.f)(),async e=>{try{if(!e)return void console.error("Please select a file");r(!0);const t=new FileReader;t.onload=async()=>{const i=t.result,s=await fetch("https://api-inference.huggingface.co/models/microsoft/resnet-50",{method:"POST",body:i,headers:{Authorization:"Bearer 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","Content-Type":"image/jpeg"}}),a=await s.json();a.error&&a.error.includes("currently loading")?(c("Model is still loading. Retrying in 20 seconds..."),setTimeout((()=>l(e)),2e4)):(n(a),c(null)),r(!1)},t.readAsArrayBuffer(e)}catch(o){console.error("Error uploading file:",o),c("Error uploading file. Please try again."),r(!1)}});return console.log(e),Object(h.jsxs)("div",{children:[Object(h.jsx)("div",{style:{width:"500px",height:"200px",border:"2px dashed #aaaaaa",position:"relative",background:"rgb(238, 238, 238)",padding:"20px",borderRadius:"10px",marginBottom:"50px"},onDragOver:e=>{e.preventDefault()},onDrop:async e=>{e.preventDefault();const i=e.dataTransfer.files[0];await l(i),t(i)},children:Object(h.jsxs)("p",{style:{position:"absolute",top:"50%",left:"50%",transform:"translate(-50%, -50%)"},children:[Object(h.jsx)("i",{class:"bi bi-card-image"})," Drop or Upload Image"]})}),Object(h.jsxs)("div",{className:"drop",children:[Object(h.jsx)("input",{type:"file",onChange:async e=>{const i=e.target.files[0];await l(i),t(i)},className:"input_btn"}),a&&Object(h.jsx)("div",{className:"div_loader"}),o&&Object(h.jsxs)("p",{children:["Error: ",o]}),e&&Object(h.jsx)("img",{src:URL.createObjectURL(e),alt:"Selected",style:{width:"500px",height:"300px",objectFit:"cover",marginTop:"50px",marginBottom:"50px"}})]}),i&&Object(h.jsxs)("div",{className:"result",children:[Object(h.jsx)("h2",{children:"Result:"}),i.map(((e,t)=>Object(h.jsxs)("div",{children:[Object(h.jsx)("p",{className:"label_",children:e.label}),Object(h.jsxs)("div",{className:"toflex",children:[Object(h.jsx)("div",{style:{height:"10px",width:"".concat(1500*e.score,"px"),background:"linear-gradient(to right, #3498db, #2ecc71)",marginBottom:"5px"}},t),Object(h.jsx)("p",{className:"label_",children:e.score})]})]})))]})]})};var w=()=>{const e=Object(s.useRef)(null);return Object(h.jsxs)("div",{children:[Object(h.jsx)(m,{}),Object(h.jsxs)("section",{className:"t1",children:[Object(h.jsxs)("div",{className:"desc1",children:[Object(h.jsx)("h4",{children:"ResNet-50 v1.5"}),Object(h.jsx)("p",{children:"ResNet model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al."}),Object(h.jsx)("p",{children:"Disclaimer: The team releasing ResNet did not write a model card for this model so this model card has been written by the Hugging Face team."}),Object(h.jsx)("h4",{children:"Model description"}),Object(h.jsx)("p",{children:"ResNet (Residual Network) is a convolutional neural network that democratized the concepts of residual learning and skip connections. This enables to train much deeper models."}),Object(h.jsx)("p",{children:"This is ResNet v1.5, which differs from the original model: in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate (~0.5% top1) than v1, but comes with a small performance drawback (~5% imgs/sec) according to Nvidia."}),Object(h.jsx)("img",{src:"https://cdn-lfs.huggingface.co/datasets/huggingface/documentation-images/cd6b9b5c48bf3bc68a5ba981c1f374f90f5c0d52f19f1d74db85e3f42eee04f8?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27resnet_architecture.png%3B+filename%3D%22resnet_architecture.png%22%3B&response-content-type=image%2Fpng&Expires=1709723854&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTcyMzg1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy9jZDZiOWI1YzQ4YmYzYmM2OGE1YmE5ODFjMWYzNzRmOTBmNWMwZDUyZjE5ZjFkNzRkYjg1ZTNmNDJlZWUwNGY4P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=I%7EAjA8nYaO1rEUsdJ0kn9r8Pl0wEI-Y%7EMqrsPWBpv%7EG8n5lDBiUk-1kXTo86FFYHr88Azxi1AuHcoYs1brEpXl%7EW97-kYL19dgxIDVlFPegtly5Xrn83lf%7EGpfFH%7E2fjLneOyM6UG%7EBDUsCNjcflejSdcZezBVV6yZ4rzZvftWsacg-8cQYOctR32WjE4Xc6MOs6tTqoDlZ60Ndjpc1xupxKWyyuV%7EEdBJu7%7E7X0mjE5xh85zEltXqfX2VnB6NMG%7EWhjbqQVDBar0FfYkjVTK34l1D5ImS7b1cIeLdxcxA6cXQR7o7NSHj-ZdVtpZ5QWW3zekRK7tE5mK7rdIKHnTg__&Key-Pair-Id=KVTP0A1DKRTAX",className:"desc1_img"}),Object(h.jsx)("h4",{children:"Intended uses & limitations"}),Object(h.jsx)("p",{children:"You can use the raw model for image classification. See the model hub to look for fine-tuned versions on a task that interests you."}),Object(h.jsx)("h4",{children:"How to use"}),Object(h.jsx)("p",{children:"Here is how to use this model to classify an image of the COCO 2017 dataset into one of the 1,000 ImageNet classes:"}),Object(h.jsxs)("div",{style:{display:"flex",flexDirection:"row",justifyContent:"space-between",gap:"20px"},children:[Object(h.jsx)("div",{className:"area_",children:Object(h.jsx)("textarea",{className:"desc_code",ref:e,readOnly:!0,value:'from transformers import AutoImageProcessor, ResNetForImageClassification\n    import torch\n    from datasets import load_dataset\n    \n    dataset = load_dataset("huggingface/cats-image")\n    image = dataset["test"]["image"][0]\n    \n    processor = AutoImageProcessor.from_pretrained("microsoft/resnet-50")\n    model = ResNetForImageClassification.from_pretrained("microsoft/resnet-50")\n    \n    inputs = processor(image, return_tensors="pt")\n    \n    with torch.no_grad():\n        logits = model(**inputs).logits\n    \n    # model predicts one of the 1000 ImageNet classes\n    predicted_label = logits.argmax(-1).item()\n    print(model.config.id2label[predicted_label])',style:{width:"100%",minHeight:"600px",fontFamily:"monospace"}})}),Object(h.jsx)("div",{className:"copy",children:Object(h.jsx)("button",{onClick:()=>{e.current&&(e.current.select(),document.execCommand("copy"))},className:"cpy",children:"\u2398 Copy"})})]})]}),Object(h.jsxs)("div",{className:"try",children:[Object(h.jsx)("img",{src:"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/10/19666dnn_cover.png",className:"final_img"}),Object(h.jsx)("h4",{children:"Try it Out"}),Object(h.jsx)("div",{children:Object(h.jsx)(y,{})})]})]})]})};i(40);var v=()=>{const e=Object(s.useRef)(null);return Object(h.jsxs)("div",{children:[Object(h.jsx)(m,{}),Object(h.jsxs)("section",{className:"t1",children:[Object(h.jsxs)("div",{className:"desc1",children:[Object(h.jsx)("h4",{children:"StarCoder2 LLM"}),Object(h.jsx)("p",{children:"StarCoder2-15B model is a 15B parameter model trained on 600+ programming languages from The Stack v2, with opt-out requests excluded. The model uses Grouped Query Attention, a context window of 16,384 tokens with a sliding window attention of 4,096 tokens, and was trained using the Fill-in-the-Middle objective on 4+ trillion tokens."}),Object(h.jsx)("p",{children:"Disclaimer: The team releasing ResNet did not write a model card for this model so this model card has been written by the Hugging Face team."}),Object(h.jsx)("h4",{children:"Model description"}),Object(h.jsx)("p",{children:"The model has been trained on source code from 600+ programming languages. The predominant language in source is English although other languages are also present. As such the model is capable to generate code snippets provided some context but the generated code is not guaranteed to work as intended. It can be inefficient, contain bugs or exploits. See the paper for an in-depth discussion of the model limitations."}),Object(h.jsx)("p",{children:"BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}),Object(h.jsx)("img",{src:"https://www.bankinghub.eu/wp-content/uploads/2023/05/text-summarization-ai-training-prediction-modes-bankinghub.png",className:"desc1_img"}),Object(h.jsx)("h4",{children:"Intended uses & limitations"}),Object(h.jsx)("p",{children:"You can use the raw model for image classification. See the model hub to look for fine-tuned versions on a task that interests you."}),Object(h.jsx)("h4",{children:"How to use"}),Object(h.jsx)("p",{children:"Here is how to use this model to classify an image of the COCO 2017 dataset into one of the 1,000 ImageNet classes:"}),Object(h.jsxs)("div",{style:{display:"flex",flexDirection:"row",justifyContent:"space-between",gap:"20px"},children:[Object(h.jsx)("div",{className:"area_",children:Object(h.jsx)("textarea",{className:"desc_code",ref:e,readOnly:!0,value:'# pip install git+https://github.com/huggingface/transformers.git # TODO: merge PR to main\n    from transformers import AutoModelForCausalLM, AutoTokenizer\n    \n    checkpoint = "bigcode/starcoder2-15b"\n    device = "cuda" # for GPU usage or "cpu" for CPU usage\n    \n    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n    # for multiple GPUs install accelerate and do model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map="auto")\n    model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n    \n    inputs = tokenizer.encode("def print_hello_world():", return_tensors="pt").to(device)\n    outputs = model.generate(inputs)\n    print(tokenizer.decode(outputs[0]))\n    ',style:{width:"100%",minHeight:"600px",fontFamily:"monospace"}})}),Object(h.jsx)("div",{className:"copy",children:Object(h.jsx)("button",{onClick:()=>{e.current&&(e.current.select(),document.execCommand("copy"))},className:"cpy",children:"\u2398 Copy"})})]})]}),Object(h.jsxs)("div",{className:"try",children:[Object(h.jsx)("img",{src:"https://assets-global.website-files.com/5f7ece8a7da656e8a25402bc/6375f420953f04fdc56aedd8_summarize.png",className:"final_img",style:{width:"500px"}}),Object(h.jsx)("h4",{children:"Try it Out"}),Object(h.jsx)("div",{children:Object(h.jsx)(u,{})})]})]})]})};var N=()=>Object(h.jsx)("div",{children:Object(h.jsxs)(O.c,{children:[Object(h.jsx)(O.a,{exact:!0,path:"/",component:x}),Object(h.jsx)(O.a,{path:"/ImageClassifierPage",component:w}),Object(h.jsx)(O.a,{path:"/Summarization",component:b}),Object(h.jsx)(O.a,{path:"/TextGeneration",component:v}),Object(h.jsx)(O.a,{path:"/TextToSpeech",component:g})]})});r.a.render(Object(h.jsx)(n.a.StrictMode,{children:Object(h.jsx)(o.a,{children:Object(h.jsx)(N,{})})}),document.getElementById("root"))}},[[41,1,2]]]);
//# sourceMappingURL=main.68f998ab.chunk.js.map